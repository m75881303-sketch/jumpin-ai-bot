import os
import io
import asyncio
import logging
from typing import Dict, Tuple, Optional

import requests
from flask import Flask

from telegram import (
    Update,
    InlineKeyboardButton,
    InlineKeyboardMarkup,
)
from telegram.constants import ChatAction
from telegram.ext import (
    Application,
    CommandHandler,
    CallbackQueryHandler,
    MessageHandler,
    ContextTypes,
    filters,
)

# -----------------------------
# LOGGING
# -----------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
)
logger = logging.getLogger("jump-bot")

# -----------------------------
# ENV
# -----------------------------
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN", "").strip()
HF_TOKEN = os.getenv("HF_TOKEN", "").strip()

if not TELEGRAM_TOKEN:
    raise RuntimeError("–ù–µ—Ç TELEGRAM_TOKEN –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è Render")

# -----------------------------
# FLASK (healthcheck for Render)
# -----------------------------
app = Flask(__name__)

@app.get("/")
def root():
    return "ok", 200

@app.get("/healthz")
def healthz():
    return "ok", 200

def run_flask():
    # Render –æ–±—ã—á–Ω–æ –ø—Ä–æ–∫–∏–¥—ã–≤–∞–µ—Ç PORT
    port = int(os.getenv("PORT", "10000"))
    # –í–∞–∂–Ω–æ: –±–µ–∑ reloader, –∏–Ω–∞—á–µ –±—É–¥–µ—Ç 2 –ø—Ä–æ—Ü–µ—Å—Å–∞
    app.run(host="0.0.0.0", port=port, debug=False, use_reloader=False)

# -----------------------------
# UI / MENU STRUCTURE
# start -> language -> main -> design -> hf models -> size -> prompt loop
# -----------------------------
LANGS = [
    ("ru", "–†—É—Å—Å–∫–∏–π"),
    ("en", "English"),
]

# –ú–æ–¥–µ–ª–∏ (–º–æ–∂–µ—à—å –º–µ–Ω—è—Ç—å/–¥–æ–±–∞–≤–ª—è—Ç—å –∫–Ω–æ–ø–∫–∞–º–∏ ‚Äî HF_MODEL –Ω–µ –Ω—É–∂–µ–Ω)
# –í–ê–ñ–ù–û: —ç—Ç–æ ID –º–æ–¥–µ–ª–∏ –Ω–∞ HuggingFace
HF_MODELS: Dict[str, str] = {
    "FLUX schnell (–±—ã—Å—Ç—Ä–æ)": "black-forest-labs/FLUX.1-schnell",
    "SDXL": "stabilityai/stable-diffusion-xl-base-1.0",
}

ASPECTS: Dict[str, Tuple[int, int]] = {
    "1:1": (1024, 1024),
    "9:16": (768, 1365),
    "16:9": (1365, 768),
}

# keys in context.user_data
K_LANG = "lang"
K_MODEL = "hf_model"
K_ASPECT = "aspect"
K_EXPECT_PROMPT = "expect_prompt"

# -----------------------------
# Helpers for keyboards
# -----------------------------
def kb_language():
    rows = []
    for code, title in LANGS:
        rows.append([InlineKeyboardButton(title, callback_data=f"lang:{code}")])
    return InlineKeyboardMarkup(rows)

def kb_main():
    return InlineKeyboardMarkup([
        [InlineKeyboardButton("üé® –î–∏–∑–∞–π–Ω —Å –ò–ò", callback_data="main:design")],
    ])

def kb_design():
    return InlineKeyboardMarkup([
        [InlineKeyboardButton("ü§ó Hugging Face", callback_data="design:hf")],
        [InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back:main")],
    ])

def kb_hf_models():
    rows = []
    for title, model_id in HF_MODELS.items():
        rows.append([InlineKeyboardButton(title, callback_data=f"hfmodel:{model_id}")])
    rows.append([InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back:design")])
    return InlineKeyboardMarkup(rows)

def kb_sizes():
    rows = []
    for a in ASPECTS.keys():
        rows.append([InlineKeyboardButton(a, callback_data=f"size:{a}")])
    rows.append([InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back:hf")])
    return InlineKeyboardMarkup(rows)

def kb_after_prompt():
    # –º–∞–ª–µ–Ω—å–∫–∞—è –ø–∞–Ω–µ–ª—å: —Ä–∞–∑–º–µ—Ä/–Ω–∞–∑–∞–¥ –≤ –º–µ–Ω—é
    return InlineKeyboardMarkup([
        [InlineKeyboardButton("üìê –†–∞–∑–º–µ—Ä", callback_data="menu:size")],
        [InlineKeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –≤ –º–µ–Ω—é", callback_data="menu:main")],
    ])

def get_lang(context: ContextTypes.DEFAULT_TYPE) -> str:
    return context.user_data.get(K_LANG, "ru")

# -----------------------------
# HuggingFace call (router)
# -----------------------------
def hf_generate_image(model_id: str, prompt: str, width: int, height: int) -> bytes:
    """
    Calls HuggingFace router inference.
    """
    if not HF_TOKEN:
        raise RuntimeError("HF_TOKEN –Ω–µ –∑–∞–¥–∞–Ω. –î–æ–±–∞–≤—å –µ–≥–æ –≤ Render ‚Üí Environment.")

    url = f"https://router.huggingface.co/hf-inference/models/{model_id}"
    headers = {
        "Authorization": f"Bearer {HF_TOKEN}",
        "Accept": "image/png",
    }

    payload = {
        "inputs": prompt,
        "parameters": {
            "width": width,
            "height": height,
        },
    }

    r = requests.post(url, headers=headers, json=payload, timeout=180)
    if r.status_code == 200:
        return r.content

    # –ü–æ—Å—Ç–∞—Ä–∞–µ–º—Å—è –ø–æ–∫–∞–∑–∞—Ç—å –ø–æ–Ω—è—Ç–Ω—É—é –æ—à–∏–±–∫—É
    try:
        err = r.json()
    except Exception:
        err = {"error": r.text}

    raise RuntimeError(f"HF error {r.status_code}: {err}")

# -----------------------------
# Handlers
# -----------------------------
async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    context.user_data[K_EXPECT_PROMPT] = False
    await update.message.reply_text(
        "–í—ã–±–µ—Ä–∏ —è–∑—ã–∫ üëá",
        reply_markup=kb_language(),
    )

async def cmd_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # –±—ã—Å—Ç—Ä—ã–π –≤—ã–∑–æ–≤ –º–µ–Ω—é –±–µ–∑ /start
    await update.message.reply_text("–ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é üëá", reply_markup=kb_main())

async def on_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    q = update.callback_query
    await q.answer()

    data = q.data or ""

    # -------- language
    if data.startswith("lang:"):
        code = data.split(":", 1)[1]
        context.user_data[K_LANG] = code
        context.user_data[K_EXPECT_PROMPT] = False
        await q.edit_message_text("–ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é üëá", reply_markup=kb_main())
        return

    # -------- main
    if data == "main:design":
        context.user_data[K_EXPECT_PROMPT] = False
        await q.edit_message_text("üé® –î–∏–∑–∞–π–Ω —Å –ò–ò ‚Äî –≤—ã–±–µ—Ä–∏ –∏—Å—Ç–æ—á–Ω–∏–∫:", reply_markup=kb_design())
        return

    # -------- design
    if data == "design:hf":
        context.user_data[K_EXPECT_PROMPT] = False
        await q.edit_message_text("ü§ó Hugging Face ‚Äî –≤—ã–±–µ—Ä–∏ –º–æ–¥–µ–ª—å:", reply_markup=kb_hf_models())
        return

    # -------- pick model
    if data.startswith("hfmodel:"):
        model_id = data.split(":", 1)[1]
        context.user_data[K_MODEL] = model_id
        context.user_data[K_EXPECT_PROMPT] = False
        await q.edit_message_text("–í—ã–±–µ—Ä–∏ —Ä–∞–∑–º–µ—Ä (—Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω):", reply_markup=kb_sizes())
        return

    # -------- pick size
    if data.startswith("size:"):
        aspect = data.split(":", 1)[1]
        context.user_data[K_ASPECT] = aspect
        context.user_data[K_EXPECT_PROMPT] = True

        model_id = context.user_data.get(K_MODEL, "")
        await q.edit_message_text(
            f"‚úçÔ∏è –û—Ç–ø—Ä–∞–≤—å —Ç–µ–∫—Å—Ç –ø—Ä–æ–º–ø—Ç–∞.\n\n"
            f"–ú–æ–¥–µ–ª—å: {model_id}\n"
            f"–†–∞–∑–º–µ—Ä: {aspect}\n\n"
            f"–ü–æ—Å–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Å—Ç–æ –ø–∏—à–∏ —Å–ª–µ–¥—É—é—â–∏–π –ø—Ä–æ–º–ø—Ç ‚Äî /start –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–µ–Ω.",
            reply_markup=kb_after_prompt(),
        )
        return

    # -------- menu shortcuts
    if data == "menu:size":
        await q.edit_message_text("–í—ã–±–µ—Ä–∏ —Ä–∞–∑–º–µ—Ä:", reply_markup=kb_sizes())
        return

    if data == "menu:main":
        context.user_data[K_EXPECT_PROMPT] = False
        await q.edit_message_text("–ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é üëá", reply_markup=kb_main())
        return

    # -------- back
    if data == "back:main":
        context.user_data[K_EXPECT_PROMPT] = False
        await q.edit_message_text("–ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é üëá", reply_markup=kb_main())
        return

    if data == "back:design":
        context.user_data[K_EXPECT_PROMPT] = False
        await q.edit_message_text("üé® –î–∏–∑–∞–π–Ω —Å –ò–ò ‚Äî –≤—ã–±–µ—Ä–∏ –∏—Å—Ç–æ—á–Ω–∏–∫:", reply_markup=kb_design())
        return

    if data == "back:hf":
        context.user_data[K_EXPECT_PROMPT] = False
        await q.edit_message_text("ü§ó Hugging Face ‚Äî –≤—ã–±–µ—Ä–∏ –º–æ–¥–µ–ª—å:", reply_markup=kb_hf_models())
        return

    # fallback
    await q.edit_message_text("–ù–µ –ø–æ–Ω—è–ª–∞ –¥–µ–π—Å—Ç–≤–∏–µ. –ù–∞–∂–º–∏ /menu", reply_markup=kb_main())

async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (update.message.text or "").strip()
    if not text:
        return

    # –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –µ—â—ë –Ω–µ –¥–æ—à—ë–ª –¥–æ —Ä–µ–∂–∏–º–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ ‚Äî –ø—Ä–æ—Å—Ç–æ –ø–æ–∫–∞–∂–µ–º –º–µ–Ω—é
    if not context.user_data.get(K_EXPECT_PROMPT, False):
        await update.message.reply_text("–ù–∞–∂–º–∏ /start –∏–ª–∏ /menu —á—Ç–æ–±—ã –æ—Ç–∫—Ä—ã—Ç—å –º–µ–Ω—é üëá", reply_markup=kb_main())
        return

    model_id = context.user_data.get(K_MODEL)
    aspect = context.user_data.get(K_ASPECT, "1:1")

    if not model_id:
        context.user_data[K_EXPECT_PROMPT] = False
        await update.message.reply_text("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏ –º–æ–¥–µ–ª—å –≤ –º–µ–Ω—é üëá", reply_markup=kb_main())
        return

    w, h = ASPECTS.get(aspect, (1024, 1024))

    try:
        await update.message.chat.send_action(ChatAction.UPLOAD_PHOTO)
        # blocking call -> to thread
        img_bytes = await asyncio.to_thread(hf_generate_image, model_id, text, w, h)

        bio = io.BytesIO(img_bytes)
        bio.name = "image.png"
        bio.seek(0)

        await update.message.reply_photo(photo=bio, caption="‚úÖ –ì–æ—Ç–æ–≤–æ!")
        # –û–°–¢–ê–Å–ú–°–Ø –≤ —Ä–µ–∂–∏–º–µ –ø—Ä–æ–º–ø—Ç–æ–≤ (—á—Ç–æ–±—ã –Ω–µ –Ω–∞–¥–æ –±—ã–ª–æ /start)
        context.user_data[K_EXPECT_PROMPT] = True

    except Exception as e:
        logger.exception("Generation failed")
        await update.message.reply_text(
            f"üòï –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:\n{e}\n\n"
            f"–ú–æ–∂–µ—à—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –¥—Ä—É–≥–æ–π –ø—Ä–æ–º–ø—Ç –∏–ª–∏ –ø–æ–º–µ–Ω—è—Ç—å —Ä–∞–∑–º–µ—Ä/–º–æ–¥–µ–ª—å.",
            reply_markup=kb_after_prompt(),
        )
        # –æ—Å—Ç–∞—ë–º—Å—è –≤ —Ä–µ–∂–∏–º–µ –ø—Ä–æ–º–ø—Ç–æ–≤
        context.user_data[K_EXPECT_PROMPT] = True

# -----------------------------
# MAIN
# -----------------------------
async def main():
    # Flask healthcheck in background thread
    flask_thread = asyncio.to_thread(run_flask)

    application = Application.builder().token(TELEGRAM_TOKEN).build()

    application.add_handler(CommandHandler("start", cmd_start))
    application.add_handler(CommandHandler("menu", cmd_menu))
    application.add_handler(CallbackQueryHandler(on_callback))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))

    await asyncio.gather(
        flask_thread,
        application.initialize(),
        application.start(),
        application.updater.start_polling(drop_pending_updates=True),
    )

if __name__ == "__main__":
    # IMPORTANT: –æ–¥–∏–Ω –ø—Ä–æ—Ü–µ—Å—Å!
    # –í Render –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ WEB_CONCURRENCY=1
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        pass
