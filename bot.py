import os
import asyncio
import logging
import threading
from io import BytesIO

import aiohttp
from flask import Flask
from telegram import (
    Update,
    InlineKeyboardButton,
    InlineKeyboardMarkup,
)
from telegram.constants import ParseMode
from telegram.ext import (
    Application,
    CommandHandler,
    CallbackQueryHandler,
    MessageHandler,
    ContextTypes,
    filters,
)

# -------------------------
# CONFIG
# -------------------------
logging.basicConfig(
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
    level=logging.INFO,
)
log = logging.getLogger("jump-bot")

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN") or os.getenv("TOKEN")
HF_TOKEN = os.getenv("HF_TOKEN")  # Hugging Face token (Read / Inference permissions)

# –û–¥–∏–Ω –≤—ã–±—Ä–∞–Ω–Ω—ã–π HF-–º–æ–¥–µ–ª—å–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç (–±–µ–∑ –º–µ–Ω—é –º–æ–¥–µ–ª–µ–π ‚Äî –∫–∞–∫ —Ç—ã –ø—Ä–æ—Å–∏–ª–∞)
# –ï—Å–ª–∏ –∑–∞—Ö–æ—á–µ—à—å –ø–æ–º–µ–Ω—è—Ç—å –º–æ–¥–µ–ª—å ‚Äî –º–µ–Ω—è–µ—à—å —Ç–æ–ª—å–∫–æ —Ç—É—Ç:
HF_MODEL = os.getenv("HF_MODEL", "runwayml/stable-diffusion-v1-5")

# –ù–æ–≤—ã–π router endpoint (api-inference –±–æ–ª—å—à–µ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)
HF_URL = f"https://router.huggingface.co/hf-inference/models/{HF_MODEL}"

PORT = int(os.getenv("PORT", "10000"))

# -------------------------
# SMALL WEB SERVER (Render needs open port)
# -------------------------
web_app = Flask(__name__)

@web_app.get("/")
def root():
    return "OK", 200

@web_app.get("/healthz")
def healthz():
    return "OK", 200

def run_web():
    # host must be 0.0.0.0 for Render
    web_app.run(host="0.0.0.0", port=PORT)

# -------------------------
# UI TEXTS
# -------------------------
TEXT = {
    "ru": {
        "choose_lang": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏ —è–∑—ã–∫:",
        "main_menu": "üè† *–ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é*\n–í—ã–±–µ—Ä–∏ —Ä–∞–∑–¥–µ–ª üëá",
        "ai_design": "üé® *–î–∏–∑–∞–π–Ω —Å –ò–ò*\n–í—ã–±–µ—Ä–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ üëá",
        "choose_provider": "–í—ã–±–µ—Ä–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ üëá",
        "choose_ratio": "–í—ã–±–µ—Ä–∏ —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è üëá",
        "send_prompt": "‚úçÔ∏è –û—Ç–ø—Ä–∞–≤—å —Ç–µ–∫—Å—Ç –ø—Ä–æ–º–ø—Ç–∞.\n\n*–†–∞–∑–º–µ—Ä:* {ratio}\n\n–ü–æ—Å–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ—Å—Ç–æ –ø–∏—à–∏ —Å–ª–µ–¥—É—é—â–∏–π –ø—Ä–æ–º–ø—Ç ‚Äî /start –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–µ–Ω.",
        "generating": "‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É‚Ä¶",
        "error_prefix": "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ üòï\n\n",
        "need_token": "–ù–µ –Ω–∞–π–¥–µ–Ω HF_TOKEN. –î–æ–±–∞–≤—å –µ–≥–æ –≤ Render ‚Üí Environment Variables.",
        "back": "‚¨ÖÔ∏è –ù–∞–∑–∞–¥",
        "provider_hf": "ü§ó Hugging Face",
        "menu_ai": "üé® –î–∏–∑–∞–π–Ω —Å –ò–ò",
        "ratio_1_1": "1:1",
        "ratio_9_16": "9:16",
        "ratio_16_9": "16:9",
        "hint_menu": "–ß—Ç–æ–±—ã –æ—Ç–∫—Ä—ã—Ç—å –º–µ–Ω—é ‚Äî –Ω–∞–∂–º–∏ /start üôÇ",
    },
    "en": {
        "choose_lang": "Please choose a language:",
        "main_menu": "üè† *Main menu*\nChoose a section üëá",
        "ai_design": "üé® *AI Design*\nChoose a provider üëá",
        "choose_provider": "Choose a provider üëá",
        "choose_ratio": "Choose image size üëá",
        "send_prompt": "‚úçÔ∏è Send your prompt text.\n\n*Size:* {ratio}\n\nAfter generation just send the next prompt ‚Äî no need for /start.",
        "generating": "‚è≥ Generating image‚Ä¶",
        "error_prefix": "Generation error üòï\n\n",
        "need_token": "HF_TOKEN is missing. Add it in Render ‚Üí Environment Variables.",
        "back": "‚¨ÖÔ∏è Back",
        "provider_hf": "ü§ó Hugging Face",
        "menu_ai": "üé® AI Design",
        "ratio_1_1": "1:1",
        "ratio_9_16": "9:16",
        "ratio_16_9": "16:9",
        "hint_menu": "To open menu ‚Äî send /start üôÇ",
    },
}

def get_lang(context: ContextTypes.DEFAULT_TYPE) -> str:
    return context.user_data.get("lang", "ru")

# -------------------------
# KEYBOARDS
# -------------------------
def kb_lang():
    return InlineKeyboardMarkup([
        [InlineKeyboardButton("üá∑üá∫ –†—É—Å—Å–∫–∏–π", callback_data="lang:ru")],
        [InlineKeyboardButton("üá¨üáß English", callback_data="lang:en")],
    ])

def kb_main(lang: str):
    t = TEXT[lang]
    return InlineKeyboardMarkup([
        [InlineKeyboardButton(t["menu_ai"], callback_data="menu:ai")],
    ])

def kb_ai_design(lang: str):
    t = TEXT[lang]
    return InlineKeyboardMarkup([
        [InlineKeyboardButton(t["provider_hf"], callback_data="provider:hf")],
        [InlineKeyboardButton(t["back"], callback_data="back:main")],
    ])

def kb_ratio(lang: str):
    t = TEXT[lang]
    return InlineKeyboardMarkup([
        [
            InlineKeyboardButton(t["ratio_1_1"], callback_data="ratio:1:1"),
            InlineKeyboardButton(t["ratio_9_16"], callback_data="ratio:9:16"),
            InlineKeyboardButton(t["ratio_16_9"], callback_data="ratio:16:9"),
        ],
        [InlineKeyboardButton(t["back"], callback_data="back:provider")],
    ])

# -------------------------
# COMMANDS
# -------------------------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # /start –≤—Å–µ–≥–¥–∞ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –≤—ã–±–æ—Ä —è–∑—ã–∫–∞ (–∫–∞–∫ —É —Ç–µ–±—è –Ω–∞ —Å–∫—Ä–∏–Ω–∞—Ö)
    await update.message.reply_text(TEXT["ru"]["choose_lang"], reply_markup=kb_lang())

# -------------------------
# CALLBACKS (buttons)
# -------------------------
async def on_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()

    data = query.data
    # log.info("callback: %s", data)

    if data.startswith("lang:"):
        lang = data.split(":", 1)[1]
        context.user_data["lang"] = lang
        # –Ω–µ —á–∏—Å—Ç–∏–º –≤–µ—Å—å user_data ‚Äî —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å —Ä–µ–∂–∏–º
        await query.edit_message_text(
            TEXT[lang]["main_menu"],
            reply_markup=kb_main(lang),
            parse_mode=ParseMode.MARKDOWN,
        )
        return

    lang = get_lang(context)
    t = TEXT[lang]

    if data == "menu:ai":
        await query.edit_message_text(
            t["ai_design"],
            reply_markup=kb_ai_design(lang),
            parse_mode=ParseMode.MARKDOWN,
        )
        return

    if data == "provider:hf":
        # –≤–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º HF (–±–µ–∑ –º–µ–Ω—é –º–æ–¥–µ–ª–µ–π)
        context.user_data["mode"] = "hf"
        await query.edit_message_text(
            t["choose_ratio"],
            reply_markup=kb_ratio(lang),
        )
        return

    if data.startswith("ratio:"):
        # —Ñ–æ—Ä–º–∞—Ç callback_data: ratio:1:1 –∏–ª–∏ ratio:9:16 –∏–ª–∏ ratio:16:9
        ratio = data.split(":", 1)[1]
        context.user_data["ratio"] = ratio
        context.user_data["mode"] = "hf"
        context.user_data["awaiting_prompt"] = True

        await query.edit_message_text(
            t["send_prompt"].format(ratio=ratio),
            parse_mode=ParseMode.MARKDOWN,
        )
        return

    if data == "back:main":
        await query.edit_message_text(
            t["main_menu"],
            reply_markup=kb_main(lang),
            parse_mode=ParseMode.MARKDOWN,
        )
        return

    if data == "back:provider":
        await query.edit_message_text(
            t["ai_design"],
            reply_markup=kb_ai_design(lang),
            parse_mode=ParseMode.MARKDOWN,
        )
        return

# -------------------------
# IMAGE GENERATION (HF router)
# -------------------------
def ratio_to_size(ratio: str) -> tuple[int, int]:
    # —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã (–∫—Ä–∞—Ç–Ω—ã–µ 8), —á—Ç–æ–±—ã SD –Ω–µ —Ä—É–≥–∞–ª—Å—è
    # 1:1 => 512x512
    # 9:16 => 512x912
    # 16:9 => 912x512
    if ratio == "9:16":
        return (512, 912)
    if ratio == "16:9":
        return (912, 512)
    return (512, 512)

async def generate_hf_image_bytes(prompt: str, ratio: str) -> bytes:
    if not HF_TOKEN:
        raise RuntimeError("HF_TOKEN_MISSING")

    width, height = ratio_to_size(ratio)

    headers = {
        "Authorization": f"Bearer {HF_TOKEN}",
        "Accept": "image/png",
    }

    payload = {
        "inputs": prompt,
        "parameters": {
            "width": width,
            "height": height,
            # –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —à–∞–≥–∏/–≥–∏–¥–∞–Ω—Å, –µ—Å–ª–∏ –∑–∞—Ö–æ—á–µ—à—å:
            # "num_inference_steps": 25,
            # "guidance_scale": 7.0,
        }
    }

    timeout = aiohttp.ClientTimeout(total=120)

    async with aiohttp.ClientSession(timeout=timeout) as session:
        async with session.post(HF_URL, headers=headers, json=payload) as resp:
            ct = resp.headers.get("content-type", "")
            body = await resp.read()

            # –£—Å–ø–µ—Ö ‚Äî –≤–µ—Ä–Ω—É–ª—Å—è –±–∏–Ω–∞—Ä–Ω—ã–π image/*
            if resp.status == 200 and ct.startswith("image/"):
                return body

            # –û—à–∏–±–∫–∞ ‚Äî –æ–±—ã—á–Ω–æ JSON
            try:
                text = body.decode("utf-8", errors="ignore")
            except Exception:
                text = str(body)

            raise RuntimeError(f"HF error {resp.status}: {text}")

async def generate_and_send(update: Update, context: ContextTypes.DEFAULT_TYPE, prompt: str):
    lang = get_lang(context)
    t = TEXT[lang]

    ratio = context.user_data.get("ratio") or "1:1"

    if not HF_TOKEN:
        await update.message.reply_text(t["need_token"])
        return

    msg = await update.message.reply_text(t["generating"])

    try:
        img_bytes = await generate_hf_image_bytes(prompt=prompt, ratio=ratio)
        bio = BytesIO(img_bytes)
        bio.name = "image.png"
        bio.seek(0)

        await update.message.reply_photo(photo=bio, caption="‚úÖ –ì–æ—Ç–æ–≤–æ!")
        # —Ä–µ–∂–∏–º –ù–ï —Å–±—Ä–∞—Å—ã–≤–∞–µ–º ‚Üí –º–æ–∂–Ω–æ —Å–ª–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π –ø—Ä–æ–º–ø—Ç —Å—Ä–∞–∑—É
        context.user_data["mode"] = "hf"
        context.user_data["awaiting_prompt"] = True

    except Exception as e:
        err = str(e)
        if "HF_TOKEN_MISSING" in err:
            err = t["need_token"]
        await update.message.reply_text(t["error_prefix"] + err)
    finally:
        # —É–¥–∞–ª—è–µ–º "–≥–µ–Ω–µ—Ä–∏—Ä—É—é..." —á—Ç–æ–±—ã –Ω–µ –∑–∞—Ö–ª–∞–º–ª—è—Ç—å
        try:
            await msg.delete()
        except Exception:
            pass

# -------------------------
# TEXT HANDLER
# -------------------------
async def on_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (update.message.text or "").strip()
    if not text:
        return

    # –∫–æ–º–∞–Ω–¥—ã –Ω–µ —Å—á–∏—Ç–∞–µ–º –ø—Ä–æ–º–ø—Ç–æ–º
    if text.startswith("/"):
        return

    mode = context.user_data.get("mode")
    ratio = context.user_data.get("ratio")

    # ‚úÖ –ì–ª–∞–≤–Ω—ã–π —Ñ–∏–∫—Å: –µ—Å–ª–∏ –≤—ã–±—Ä–∞–Ω HF + —Ä–∞–∑–º–µ—Ä, —Ç–æ –õ–Æ–ë–û–ô —Ç–µ–∫—Å—Ç = –ø—Ä–æ–º–ø—Ç
    if mode == "hf" and ratio:
        await generate_and_send(update, context, prompt=text)
        return

    # –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç (–µ—Å–ª–∏ –≤–¥—Ä—É–≥ ratio –µ—â—ë –Ω–µ –≤—ã–±—Ä–∞–ª–∏)
    if context.user_data.get("awaiting_prompt"):
        await generate_and_send(update, context, prompt=text)
        return

    lang = get_lang(context)
    await update.message.reply_text(TEXT[lang]["hint_menu"])

# -------------------------
# MAIN
# -------------------------
def main():
    if not TELEGRAM_TOKEN:
        raise RuntimeError("–ù–µ—Ç TELEGRAM_TOKEN (–∏–ª–∏ TOKEN) –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")

    # –∑–∞–ø—É—Å–∫–∞–µ–º web (–ø–æ—Ä—Ç) –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ ‚Äî Render –±—É–¥–µ—Ç —Å—á–∞—Å—Ç–ª–∏–≤
    threading.Thread(target=run_web, daemon=True).start()

    app = Application.builder().token(TELEGRAM_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CallbackQueryHandler(on_callback))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_text))

    # –í–∞–∂–Ω–æ: —Ä–æ–≤–Ω–æ 1 –∏–Ω—Å—Ç–∞–Ω—Å –Ω–∞ Render, –∏–Ω–∞—á–µ –±—É–¥–µ—Ç Conflict getUpdates
    app.run_polling(drop_pending_updates=True)

if __name__ == "__main__":
    main()
